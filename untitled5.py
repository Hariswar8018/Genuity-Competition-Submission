# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o9NcoShseTE65E5UTpV6Dp3Txm5DwEkr
"""

!pip install sdv --quiet

import pandas as pd
from sdv.metadata import SingleTableMetadata
from sdv.single_table import CTGANSynthesizer

df = pd.read_csv("/content/real_0.6.csv")

metadata = SingleTableMetadata()
metadata.detect_from_dataframe(df)

lens = 3322

def submit(data, subname):
    df = data.copy()

    # ---- Fill missing values ----
    # Fill categorical (object or category) columns with "ADANIPORT"
    for col in df.select_dtypes(include=["object", "category"]).columns:
        df[col] = df[col].fillna("ADANIPORTS")

    # Fill numerical columns with column mean
    for col in df.select_dtypes(include=["number"]).columns:
        df[col] = df[col].fillna(df[col].mean())

    # ---- Continue with your original logic ----
    df = df.sort_values("t").reset_index(drop=True)
    df["row_id_column_name"] = range(1, len(df) + 1)

    if "Series" in df.columns:
        df = df.drop(columns=["Series"])

    submission_cols = [
        "row_id_column_name", "Symbol", "Prev Close", "Open", "High", "Low",
        "Last", "Close", "VWAP", "Volume", "Turnover", "Trades",
        "Deliverable Volume", "%Deliverble", "t"
    ]

    df = df[submission_cols]
    df.to_csv(f"{subname}.csv", index=False)

    print("Done! Matched EXACT submission format.")
    print("Done! Saved as", subname, ".csv file submission done.")

import pandas as pd
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error

def evaluate_predictions(original_df, synthetic_df):
    """
    Comprehensive evaluation for synthetic data
    """
    results = {}
    numerical_cols = original_df.select_dtypes(include=[np.number]).columns

    for col in numerical_cols:
        if col in synthetic_df.columns:
            # Remove NaNs
            mask = (~original_df[col].isna()) & (~synthetic_df[col].isna())
            orig = original_df[col][mask]
            synth = synthetic_df[col][mask]

            if len(orig) > 10:
                from scipy.stats import wasserstein_distance, ks_2samp

                metrics = {
                    # Basic error metrics
                    'rmse': np.sqrt(mean_squared_error(orig, synth)),
                    'mae': np.mean(np.abs(orig - synth)),

                    # Statistical similarity
                    'wasserstein_distance': wasserstein_distance(orig, synth),
                    'ks_statistic': ks_2samp(orig, synth).statistic,

                    # Distribution preservation
                    'mean_ratio': synth.mean() / orig.mean(),
                    'std_ratio': synth.std() / orig.std(),

                    # Correlation preservation (if you have multiple samples)
                    'r2_score': r2_score(orig, synth)
                }

                results[col] = metrics

    return results

def print_summary(results):
    print("COMPREHENSIVE SYNTHETIC DATA EVALUATION")
    print("=" * 60)

    for col, metrics in results.items():
        print(f"\n{col}:")
        print(f"  Wasserstein Distance: {metrics['wasserstein_distance']:.4f} (lower = better)")
        print(f"  KS Statistic: {metrics['ks_statistic']:.4f} (lower = better)")
        print(f"  Mean Ratio: {metrics['mean_ratio']:.4f} (closer to 1.0 = better)")
        print(f"  Std Ratio: {metrics['std_ratio']:.4f} (closer to 1.0 = better)")
        print(f"  R2 Score: {metrics['r2_score']:.4f}")

def assess_synthetic_quality(results):
    """Quick quality assessment"""
    print("QUALITY ASSESSMENT:")
    print("=" * 40)

    good_columns = 0
    total_columns = len(results)

    for col, metrics in results.items():
        quality_issues = []

        if metrics['wasserstein_distance'] > 0.3:
            quality_issues.append("poor distribution match")
        if abs(metrics['std_ratio'] - 1.0) > 0.2:
            quality_issues.append("variance not preserved")
        if abs(metrics['mean_ratio'] - 1.0) > 0.1:
            quality_issues.append("mean shifted")

        if not quality_issues:
            print(f"✓ {col}: GOOD")
            good_columns += 1
        else:
            print(f"✗ {col}: Issues - {', '.join(quality_issues)}")

    print(f"\nOverall Quality: {good_columns}/{total_columns} columns passed")
    return good_columns / total_columns

"""# CTGAN Model"""

def preprocess_for_ctgan(df,
                         categorical_cols=['Symbol','Series'],
                         exclude_cols=['t']):
    df_processed = df.copy()

    # Numerical columns excluding categorical + exclude
    numeric_cols = [
        col for col in df.columns
        if col not in categorical_cols + exclude_cols
        and np.issubdtype(df[col].dtype, np.number)
    ]

    # Store min/max/skew for reversing
    stats = {}

    for col in numeric_cols:
        col_stats = {}

        # Log transform (high skew)
        skew_val = df[col].skew()
        col_stats['log'] = skew_val > 10

        if col_stats['log']:
            df_processed[col] = np.log1p(df_processed[col])

        # Normalize
        min_val = df_processed[col].min()
        max_val = df_processed[col].max()

        if max_val > min_val:
            df_processed[col] = (df_processed[col] - min_val) / (max_val - min_val)

        # Save stats
        col_stats['min'] = min_val
        col_stats['max'] = max_val
        stats[col] = col_stats

    return df_processed, stats

def postprocess_synthetic_data(synthetic_df, stats,
                               categorical_cols=['Symbol','Series']):
    df_out = synthetic_df.copy()

    for col, col_stats in stats.items():
        # clip values to [0,1] if CTGAN overshoots
        df_out[col] = df_out[col].clip(0,1)

        # reverse normalization
        df_out[col] = df_out[col] * (col_stats['max'] - col_stats['min']) + col_stats['min']

        # reverse log transform
        if col_stats['log']:
            df_out[col] = np.expm1(df_out[col])

    return df_out

categorical = ["Symbol", "Series"]

df_prep, stats = preprocess_for_ctgan(df, categorical_cols=categorical, exclude_cols=['t'])

df2 = df_prep.copy()

ctgan = CTGANSynthesizer(
     metadata=metadata,
        epochs=100,
        generator_dim=(512, 512, 512, 512),
        discriminator_dim=(512, 512, 512, 512),
        generator_lr=2e-4,
        discriminator_lr=2e-4,
        pac=10,
        cuda=True,
)
ctgan.fit(df2)

ctgan.save("CTGAN_model.pkl")

df_syn = ctgan.sample(num_rows=lens)

df_syn.to_csv("synthetic_CTGAN.csv", index=False)

print("CTGAN training completed and files saved.")
#submit(df_syn, "CTGAN_submission_100")
results = evaluate_predictions(df2, df_syn.iloc[0:len(df2)])
assess_synthetic_quality(results)

test = postprocess_synthetic_data(df_syn, stats)
results = evaluate_predictions(df, test.iloc[0:len(df)])
assess_synthetic_quality(results)
submit(test, "CTGAN")

df['t']

def debug_data_issues(original_df, synthetic_df):
    """
    Check what's happening with the data
    """
    print("DEBUG INFO:")
    print("=" * 40)

    numerical_cols = original_df.select_dtypes(include=[np.number]).columns

    for col in numerical_cols:
        if col in synthetic_df.columns:
            orig = original_df[col].dropna()
            synth = synthetic_df[col].dropna()

            print(f"\n{col}:")
            print(f"Original stats: mean={orig.mean():.2f}, std={orig.std():.2f}")
            print(f"Synthetic stats: mean={synth.mean():.2f}, std={synth.std():.2f}")
            print(f"Original range: [{orig.min():.2f}, {orig.max():.2f}]")
            print(f"Synthetic range: [{synth.min():.2f}, {synth.max():.2f}]")

            # Check for NaN/inf
            print(f"Original NaNs: {orig.isna().sum()}, Synthetic NaNs: {synth.isna().sum()}")

# Run debug
debug_data_issues(df, test)

"""# TVAE - TRAIN & SAVE"""

import pandas as pd
from sdv.metadata import SingleTableMetadata
from sdv.single_table import TVAESynthesizer

tvae = TVAESynthesizer(metadata, epochs=100)
tvae.fit(df)

tvae.save("TVAE_model.pkl")

df_syn2 = tvae.sample(num_rows=len(df))
results = evaluate_predictions(df, df_syn2.iloc[0:len(df)])
assess_synthetic_quality(results)
#submit(df_syn2, "TVAE_submission_50s")

"""# Gaussian Copla"""

import pandas as pd
from sdv.metadata import SingleTableMetadata
from sdv.single_table import GaussianCopulaSynthesizer


gc = GaussianCopulaSynthesizer(
    metadata
    )
gc.fit(df)

gc.save("GaussianCopula_model.pkl")

df_syn3 = gc.sample(num_rows=lens)
results = evaluate_predictions(df, df_syn3.iloc[0:len(df)])
assess_synthetic_quality(results)
#submit(df_syn3, "Gaussian_submission")

"""# CopulaGAN"""

import pandas as pd
from sdv.metadata import SingleTableMetadata
from sdv.single_table import CopulaGANSynthesizer

cgan = CopulaGANSynthesizer(
    metadata, epochs=200,verbose=True,
    )
cgan.fit(df)

cgan.save("CopulaGAN_model.pkl")

# Generate synthetic data
df_syn4 = cgan.sample(num_rows=lens)

results = evaluate_predictions(df, df_syn4.iloc[0:len(df)])
assess_synthetic_quality(results)
#submit(df_syn4, "CopulaGaussian_submission_100")

"""# Evaluation Metrics"""

